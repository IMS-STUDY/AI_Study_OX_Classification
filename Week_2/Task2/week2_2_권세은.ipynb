{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2sqVmvBCalB",
        "outputId": "bd882103-3c9a-4794-85f0-48f2899fc980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RgvEQ_vTDOtP"
      },
      "outputs": [],
      "source": [
        "# 기본 설정\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LeakyReLU # 활성화 함수 직접 사용하려 했지만 함수 인식 못함 -> import해서 해결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UVJwnUlETOm",
        "outputId": "c5aa11ca-216e-4241-af94-e63f847d740e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        }
      ],
      "source": [
        "# 데이터세트 경로 설정\n",
        "dataset_path = '/content/drive/MyDrive/Dataset/Dataset/'\n",
        "\n",
        "# 증강된 데이터세트를 저장할 경로 설정\n",
        "augmented_dataset_path = '/content/drive/MyDrive/Dataset/AugmentedDataset/'\n",
        "\n",
        "# 이미지 파일 목록과 라벨 생성\n",
        "image_files = []\n",
        "labels = []\n",
        "for filename in os.listdir(dataset_path):\n",
        "  if filename.endswith(('.png','.jpg')):    #filename 중 .png, .jpg로 끝나는 것 찾기\n",
        "    image_files.append(os.path.join(dataset_path, filename))\n",
        "    if 'o' in filename:    # filename = o라면 0\n",
        "      labels.append(0)\n",
        "    elif 'x' in filename:  # filename = x라면 1\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(2)     # o, x 둘다 아니라면 2\n",
        "\n",
        "# 디버깅\n",
        "print(len(image_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox73jnDtzUXV",
        "outputId": "f99543a5-3e7c-4b69-df04-01e53f6c5138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        }
      ],
      "source": [
        "# 데이터 개수 늘리기(좌우반전, 노이즈 추가 etc)\n",
        "flipped_count = 0 #좌우반전 된 이미지의 개수를 세기위해 필요\n",
        "for image_file in image_files:\n",
        "  image_path = os.path.join(dataset_path, image_file)\n",
        "  flipped_count += 1  #이미지 반전 후 카운터 1 증가\n",
        "\n",
        "  # 이미지 읽기\n",
        "  img = cv2.imread(image_path)\n",
        "\n",
        "  # 좌우반전\n",
        "  flipped_img =cv2.flip(img, 1)\n",
        "\n",
        "  # 파일 이름 생성 (원본 파일 이름에 _flipped 추가)\n",
        "  name, ext = os.path.splitext(image_file)\n",
        "  flipped_image_file = f\"{name}_flipped{ext}\"\n",
        "  flipped_image_path = os.path.join(augmented_dataset_path, flipped_image_file)\n",
        "\n",
        "  #좌우반전 된 이미지 저장\n",
        "  cv2.imwrite(flipped_image_path, flipped_img)\n",
        "\n",
        "# 디버깅\n",
        "print(flipped_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtcJozZOrKpm",
        "outputId": "446d0394-761a-418c-e750-e9ee2ffcdd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(360, 300, 300, 3)\n",
            "(360,)\n",
            "[[[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# 이미지 데이터세트 생성 (tf.data.Dataset 사용)\n",
        "image_size = (300, 300)\n",
        "BATCH_SIZE = 8 #batch size : 소그룹에 속하는 데이터\n",
        "BUFFER_SIZE = tf.data.AUTOTUNE #시스템과 데이터세트에 맞춰 버퍼 크기 자동 조정\n",
        "\n",
        "# 이미지 전처리\n",
        "def preprocess_image(image_path, target_size = (300, 300)):\n",
        "  img = tf.keras.preprocessing.image.load_img(image_path, target_size = target_size) #이미지 불러오기\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img) #이미지 배열 변환\n",
        "  img = img / 255.0 #픽셀 값 정규화\n",
        "  return img\n",
        "\n",
        "# 이미지 데이터와 라벨을 Numpy 배열로 변환\n",
        "images = np.array([preprocess_image(image_file) for image_file in image_files])\n",
        "labels = np.array(labels)\n",
        "\n",
        "#디버깅\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "print(images[0])\n",
        "print(labels[0])  #우연히 x 파일 선택?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnpIh0PIw5Lw",
        "outputId": "1ced6a05-d410-41ec-98b1-fbf13fb248e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        }
      ],
      "source": [
        "# 생성한 flipped 파일 삭제하기\n",
        "augmented_dataset_path = '/content/drive/MyDrive/Dataset/Dataset/'\n",
        "\n",
        "# augmented_dataset_path 디렉토리 내의 파일 목록 가져오기\n",
        "for filename in os.listdir(augmented_dataset_path):\n",
        "  if \"flipped\" in filename:  # 파일 이름에 \"flipped\"가 포함된 파일 찾기\n",
        "    file_path = os.path.join(augmented_dataset_path, filename)\n",
        "    os.remove(file_path)  # 파일 삭제\n",
        "\n",
        "# 디버깅\n",
        "print(flipped_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJV0HC-cjYtU",
        "outputId": "6b21a619-0b2e-4acb-948a-c5a9d5e61903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288, 300, 300, 3)\n",
            "(72, 300, 300, 3)\n",
            "(288,)\n",
            "(72,)\n"
          ]
        }
      ],
      "source": [
        "# 훈련 데이터세트, 테스트 데이터세트로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# 디버깅\n",
        "print(x_train.shape) #훈련 데이터세트에 있는 이미지의 개수, tragetsize(300, 300), 채널(RGB)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TsyDIxzkibb",
        "outputId": "9bac8a59-34d4-4baa-9e93-c07d76e24b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 765ms/step - accuracy: 0.5556 - loss: 7.5820 - val_accuracy: 0.5417 - val_loss: 1.7956\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7903 - loss: 0.6872 - val_accuracy: 0.8056 - val_loss: 0.4546\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9006 - loss: 0.2346 - val_accuracy: 0.8056 - val_loss: 0.4706\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9720 - loss: 0.0869 - val_accuracy: 0.8194 - val_loss: 0.3815\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9913 - loss: 0.0325 - val_accuracy: 0.8194 - val_loss: 0.3350\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.8056 - val_loss: 0.4099\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8056 - val_loss: 0.4733\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 1.9839e-04 - val_accuracy: 0.8056 - val_loss: 0.5305\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.6247e-04 - val_accuracy: 0.8194 - val_loss: 0.5108\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.2108e-04 - val_accuracy: 0.8194 - val_loss: 0.5120\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.0306e-04 - val_accuracy: 0.8194 - val_loss: 0.5084\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.0630e-04 - val_accuracy: 0.8056 - val_loss: 0.5068\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 7.3930e-05 - val_accuracy: 0.8194 - val_loss: 0.6022\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 3.2708e-05 - val_accuracy: 0.8056 - val_loss: 0.5890\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 3.5765e-05 - val_accuracy: 0.8056 - val_loss: 0.5207\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 5.3751e-05 - val_accuracy: 0.8056 - val_loss: 0.5580\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 6.3158e-05 - val_accuracy: 0.8056 - val_loss: 0.6150\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 2.4927e-05 - val_accuracy: 0.8194 - val_loss: 0.6405\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.4291e-05 - val_accuracy: 0.8194 - val_loss: 0.5547\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.8246e-05 - val_accuracy: 0.8056 - val_loss: 0.5553\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.3171e-05 - val_accuracy: 0.8056 - val_loss: 0.5887\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.4396e-05 - val_accuracy: 0.8194 - val_loss: 0.6031\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 8.6122e-06 - val_accuracy: 0.8194 - val_loss: 0.6053\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 9.7447e-06 - val_accuracy: 0.8056 - val_loss: 0.6026\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.5332e-05 - val_accuracy: 0.8194 - val_loss: 0.6167\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.7058e-05 - val_accuracy: 0.8056 - val_loss: 0.5932\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 9.8399e-06 - val_accuracy: 0.8194 - val_loss: 0.6235\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 9.1745e-06 - val_accuracy: 0.8194 - val_loss: 0.6106\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.3750e-05 - val_accuracy: 0.8056 - val_loss: 0.6037\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 8.1832e-06 - val_accuracy: 0.8056 - val_loss: 0.6158\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.4552e-05 - val_accuracy: 0.8194 - val_loss: 0.6459\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 8.3410e-06 - val_accuracy: 0.8333 - val_loss: 0.6277\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 8.5542e-06 - val_accuracy: 0.8056 - val_loss: 0.6125\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 7.1231e-06 - val_accuracy: 0.8194 - val_loss: 0.6178\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 8.7580e-06 - val_accuracy: 0.8194 - val_loss: 0.6389\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.0068e-05 - val_accuracy: 0.8194 - val_loss: 0.6186\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 5.1389e-06 - val_accuracy: 0.8194 - val_loss: 0.6220\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 5.3892e-06 - val_accuracy: 0.8333 - val_loss: 0.6363\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 5.2677e-06 - val_accuracy: 0.8333 - val_loss: 0.6331\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 6.6004e-06 - val_accuracy: 0.8194 - val_loss: 0.6257\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 8.8091e-06 - val_accuracy: 0.8194 - val_loss: 0.6281\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 8.5773e-06 - val_accuracy: 0.8333 - val_loss: 0.6373\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 5.8500e-06 - val_accuracy: 0.8333 - val_loss: 0.6439\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.4082e-06 - val_accuracy: 0.8333 - val_loss: 0.6478\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 6.7466e-06 - val_accuracy: 0.8194 - val_loss: 0.6394\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 7.4570e-06 - val_accuracy: 0.8194 - val_loss: 0.6395\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 6.5209e-06 - val_accuracy: 0.8194 - val_loss: 0.6213\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 6.7766e-06 - val_accuracy: 0.8194 - val_loss: 0.6306\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 3.4086e-06 - val_accuracy: 0.8194 - val_loss: 0.6370\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.0381e-06 - val_accuracy: 0.8194 - val_loss: 0.6381\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8316 - loss: 0.5760\n",
            "accuracy: 0.8194444179534912\n",
            "기본모델 : 81.94444179534912%\n"
          ]
        }
      ],
      "source": [
        "# 모델 구성1 : 기본 모델\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(30, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(60, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# layers.Conv2D : 합성곱 레이어 -> 30 : 30개의 필터 사용(다른 숫자 사용가능) / 필터 크기 3x3 / 픽셀크기 300x300 + 3개의 채널(빨,파,초)\n",
        "# layers.MaxPooling2D : 최대 풀링 레이어 -> 이미지 크기 줄이고 중요한 특징 강조\n",
        "# layers.Conv2D : 합성곱 레이어 -> 60개의 필터를 사용하여 더 많은 특징 추출\n",
        "# layers.MaxPooling2D : 최대 풀링 레이어 -> 이미지 크기를 더 줄임\n",
        "# layers.Flatten : 플래튼 레이어 -> 다차원 데이터를 1차원으로 변환\n",
        "# layers.Dense : 완전 연결 레이어 -> 모든 입력 노드가 모든 출력 노드에 연결됨(120개의 노드를 가지고 있음)\n",
        "# layers.Dense : 완전 연결 레이어 -> 최종 출력 레이어 -> 3개의 클래스 분류\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# optimizer='adam' : 학습 중 오차를 줄이기 위해 모델이 가중치를 업데이트하는 방법 제어\n",
        "# sparse_categorical_crossentropy : 정수형 -> 모델의 예측과 실제 목표 값 사이 차이를 정량화하는 함수\n",
        "# metrics=['accuracy'] : 학습 중 모델의 성능을 평가하는데 사용\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs = 50, validation_data=(x_test, y_test))\n",
        "# model.fit : 저장된 모델을 학습시키는 함수\n",
        "# 훈련 데이터 : x_train(이미지 데이터), y_train(o, x 구분)\n",
        "# epochs : 모든 데이터셋을 학습하는 횟수\n",
        "# validation_data : 모델의 성능 검증\n",
        "# x_test : 검증용 이미지 데이터, y_test : 검증용 이미지에 대한 정답\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'기본모델 : {accuracy*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpxx9jSkEyY9",
        "outputId": "81165d41-6282-4c27-c27c-f1d5a7cf3edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 834ms/step - accuracy: 0.4884 - loss: 1.4630 - val_accuracy: 0.5278 - val_loss: 0.6912\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.5011 - loss: 0.7248 - val_accuracy: 0.7361 - val_loss: 0.6474\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.6882 - loss: 0.6004 - val_accuracy: 0.7500 - val_loss: 0.5302\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.7908 - loss: 0.4049 - val_accuracy: 0.7778 - val_loss: 0.4218\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.8585 - loss: 0.2807 - val_accuracy: 0.8611 - val_loss: 0.2316\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.8896 - loss: 0.2225 - val_accuracy: 0.8750 - val_loss: 0.1928\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9509 - loss: 0.1211 - val_accuracy: 0.9167 - val_loss: 0.1750\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9804 - loss: 0.0782 - val_accuracy: 0.9167 - val_loss: 0.2627\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9572 - loss: 0.0721 - val_accuracy: 0.9167 - val_loss: 0.2464\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.9765 - loss: 0.0568 - val_accuracy: 0.8889 - val_loss: 0.3283\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9924 - loss: 0.0309 - val_accuracy: 0.9028 - val_loss: 0.3652\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9167 - val_loss: 0.4227\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9167 - val_loss: 0.5390\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9167 - val_loss: 0.5823\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.0198e-04 - val_accuracy: 0.9167 - val_loss: 0.6160\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 4.2338e-04 - val_accuracy: 0.9167 - val_loss: 0.6336\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 5.2965e-04 - val_accuracy: 0.9028 - val_loss: 0.6652\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 2.3139e-04 - val_accuracy: 0.8750 - val_loss: 0.6838\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.0068e-04 - val_accuracy: 0.8889 - val_loss: 0.6965\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 6.7418e-05 - val_accuracy: 0.9028 - val_loss: 0.7095\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 7.7025e-05 - val_accuracy: 0.9028 - val_loss: 0.7222\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 6.9937e-05 - val_accuracy: 0.9028 - val_loss: 0.7396\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 7.1111e-05 - val_accuracy: 0.9028 - val_loss: 0.7520\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.0774e-05 - val_accuracy: 0.9028 - val_loss: 0.7628\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 3.8592e-05 - val_accuracy: 0.9028 - val_loss: 0.7722\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 2.9026e-05 - val_accuracy: 0.9028 - val_loss: 0.7797\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.1346e-05 - val_accuracy: 0.9028 - val_loss: 0.7858\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 1.9595e-05 - val_accuracy: 0.9028 - val_loss: 0.7928\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 9.6888e-06 - val_accuracy: 0.9028 - val_loss: 0.8000\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 2.5107e-05 - val_accuracy: 0.9028 - val_loss: 0.8072\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 2.6409e-05 - val_accuracy: 0.9028 - val_loss: 0.8129\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.3736e-05 - val_accuracy: 0.9028 - val_loss: 0.8218\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 6.5028e-06 - val_accuracy: 0.9028 - val_loss: 0.8271\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 1.2209e-05 - val_accuracy: 0.9028 - val_loss: 0.8328\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.0311e-05 - val_accuracy: 0.9028 - val_loss: 0.8390\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 5.0017e-06 - val_accuracy: 0.9028 - val_loss: 0.8442\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 6.8785e-06 - val_accuracy: 0.9028 - val_loss: 0.8492\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 5.0295e-06 - val_accuracy: 0.9028 - val_loss: 0.8532\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 7.6310e-06 - val_accuracy: 0.9028 - val_loss: 0.8581\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 5.9340e-06 - val_accuracy: 0.9028 - val_loss: 0.8632\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 5.0341e-06 - val_accuracy: 0.9028 - val_loss: 0.8676\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 2.1892e-06 - val_accuracy: 0.9028 - val_loss: 0.8707\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 3.7565e-06 - val_accuracy: 0.9028 - val_loss: 0.8748\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 2.6595e-06 - val_accuracy: 0.9028 - val_loss: 0.8791\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 4.2468e-06 - val_accuracy: 0.9028 - val_loss: 0.8809\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 3.5477e-06 - val_accuracy: 0.9028 - val_loss: 0.8839\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 2.2599e-06 - val_accuracy: 0.9028 - val_loss: 0.8898\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 3.1208e-06 - val_accuracy: 0.9028 - val_loss: 0.8919\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.5661e-06 - val_accuracy: 0.9028 - val_loss: 0.8948\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.3789e-06 - val_accuracy: 0.9028 - val_loss: 0.8990\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9201 - loss: 0.6870 \n",
            "accuracy: 0.9027777910232544\n",
            "컨볼루션 추가 모델 : 90.27777910232544%\n"
          ]
        }
      ],
      "source": [
        "# 모델 구성2 : 컨볼루션 추가\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300,300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'컨볼루션 추가 모델 : {accuracy*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성3 : elu 모델\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='elu', input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='elu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='elu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'elu 모델 : {accuracy*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmNnWpl7Nbk3",
        "outputId": "1a98d4bf-7492-47af-db0a-452d896df34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 451ms/step - accuracy: 0.3527 - loss: 60.2731 - val_accuracy: 0.4583 - val_loss: 13.2797\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4583 - loss: 8.8545 - val_accuracy: 0.5417 - val_loss: 0.8720\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.4502 - loss: 1.7165 - val_accuracy: 0.4583 - val_loss: 0.9782\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5398 - loss: 0.9871 - val_accuracy: 0.5417 - val_loss: 0.6914\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4864 - loss: 1.0953 - val_accuracy: 0.7778 - val_loss: 0.6649\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5680 - loss: 0.9173 - val_accuracy: 0.4583 - val_loss: 0.7001\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.5091 - loss: 1.0004 - val_accuracy: 0.4583 - val_loss: 0.7103\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.5165 - loss: 1.0149 - val_accuracy: 0.4583 - val_loss: 0.7097\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.5183 - loss: 1.0321 - val_accuracy: 0.5417 - val_loss: 0.6901\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.4670 - loss: 1.1372 - val_accuracy: 0.5417 - val_loss: 0.6897\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5219 - loss: 0.9750 - val_accuracy: 0.4722 - val_loss: 0.6930\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.5059 - loss: 0.9388 - val_accuracy: 0.5417 - val_loss: 0.6886\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.4863 - loss: 0.9911 - val_accuracy: 0.4722 - val_loss: 0.6956\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4547 - loss: 1.1151 - val_accuracy: 0.4722 - val_loss: 0.6980\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4954 - loss: 1.0045 - val_accuracy: 0.4722 - val_loss: 0.6938\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.4528 - loss: 1.0921 - val_accuracy: 0.5417 - val_loss: 0.6871\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.5344 - loss: 0.9560 - val_accuracy: 0.5417 - val_loss: 0.6875\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.5333 - loss: 0.9143 - val_accuracy: 0.4583 - val_loss: 0.6978\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4845 - loss: 1.0500 - val_accuracy: 0.4583 - val_loss: 0.6930\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4933 - loss: 0.9839 - val_accuracy: 0.6667 - val_loss: 0.6800\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.5486 - loss: 0.8676 - val_accuracy: 0.4861 - val_loss: 0.6854\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.4966 - loss: 1.0383 - val_accuracy: 0.5417 - val_loss: 0.6837\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.5113 - loss: 1.0071 - val_accuracy: 0.4722 - val_loss: 0.6913\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5581 - loss: 0.9382 - val_accuracy: 0.4722 - val_loss: 0.6898\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4956 - loss: 0.9705 - val_accuracy: 0.5972 - val_loss: 0.6806\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.5148 - loss: 1.0287 - val_accuracy: 0.7500 - val_loss: 0.6709\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5705 - loss: 0.8612 - val_accuracy: 0.7500 - val_loss: 0.6564\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.5451 - loss: 0.8471 - val_accuracy: 0.5972 - val_loss: 0.6563\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.4959 - loss: 1.0050 - val_accuracy: 0.5417 - val_loss: 0.6972\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.5018 - loss: 0.9371 - val_accuracy: 0.4722 - val_loss: 0.6941\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.5015 - loss: 0.9537 - val_accuracy: 0.5417 - val_loss: 0.6860\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.4970 - loss: 0.9778 - val_accuracy: 0.5417 - val_loss: 0.6880\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.5263 - loss: 0.9793 - val_accuracy: 0.4861 - val_loss: 0.6756\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.5163 - loss: 0.9632 - val_accuracy: 0.7639 - val_loss: 0.6545\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.5172 - loss: 0.9601 - val_accuracy: 0.6528 - val_loss: 0.6582\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5398 - loss: 0.9465 - val_accuracy: 0.5694 - val_loss: 0.6608\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.4875 - loss: 1.0104 - val_accuracy: 0.5417 - val_loss: 0.6791\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5162 - loss: 0.9982 - val_accuracy: 0.6250 - val_loss: 0.6802\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.5791 - loss: 0.8376 - val_accuracy: 0.4583 - val_loss: 0.6863\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5731 - loss: 0.9276 - val_accuracy: 0.7778 - val_loss: 0.6662\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.4537 - loss: 1.0018 - val_accuracy: 0.5417 - val_loss: 0.6607\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.5561 - loss: 0.9023 - val_accuracy: 0.4583 - val_loss: 0.7087\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4980 - loss: 1.0005 - val_accuracy: 0.4583 - val_loss: 0.7000\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.5015 - loss: 0.9782 - val_accuracy: 0.4583 - val_loss: 0.6903\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.5002 - loss: 0.9943 - val_accuracy: 0.4861 - val_loss: 0.6966\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.4987 - loss: 0.9601 - val_accuracy: 0.5417 - val_loss: 0.6798\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.4747 - loss: 1.0767 - val_accuracy: 0.5417 - val_loss: 0.6779\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4847 - loss: 0.9548 - val_accuracy: 0.5417 - val_loss: 0.6709\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.4867 - loss: 0.8944 - val_accuracy: 0.4583 - val_loss: 0.7014\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.4611 - loss: 1.0187 - val_accuracy: 0.5139 - val_loss: 0.6764\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4913 - loss: 0.6800\n",
            "accuracy: 0.5138888955116272\n",
            "elu 모델 : 51.38888955116272%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlbRq-YTAwdE",
        "outputId": "280e1c63-13c5-49d6-80b5-5b88652aed93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - accuracy: 0.5855 - loss: 15.0996 - val_accuracy: 0.4583 - val_loss: 24.9812\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9128 - loss: 2.9817 - val_accuracy: 0.4583 - val_loss: 17.1730\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9285 - loss: 0.9084 - val_accuracy: 0.4861 - val_loss: 28.0336\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9613 - loss: 0.4447 - val_accuracy: 0.5000 - val_loss: 24.9539\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9773 - loss: 0.3646 - val_accuracy: 0.4861 - val_loss: 35.1967\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9870 - loss: 0.2669 - val_accuracy: 0.5278 - val_loss: 20.0452\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9945 - loss: 0.0616 - val_accuracy: 0.6250 - val_loss: 6.1066\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9871 - loss: 0.0940 - val_accuracy: 0.5972 - val_loss: 9.6212\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9869 - loss: 0.3800 - val_accuracy: 0.5278 - val_loss: 19.0398\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9856 - loss: 0.0851 - val_accuracy: 0.5139 - val_loss: 15.5249\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9826 - loss: 0.0419 - val_accuracy: 0.6250 - val_loss: 6.6064\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9967 - loss: 0.0280 - val_accuracy: 0.6111 - val_loss: 4.7218\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9965 - loss: 0.0252 - val_accuracy: 0.5556 - val_loss: 12.4044\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9958 - loss: 0.0169 - val_accuracy: 0.6250 - val_loss: 4.0136\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9939 - loss: 0.0601 - val_accuracy: 0.8333 - val_loss: 1.1867\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9966 - loss: 0.0413 - val_accuracy: 0.7778 - val_loss: 2.0865\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9939 - loss: 0.0249 - val_accuracy: 0.7778 - val_loss: 2.3934\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9940 - loss: 0.0837 - val_accuracy: 0.8472 - val_loss: 1.6463\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9979 - loss: 0.0021 - val_accuracy: 0.7639 - val_loss: 1.7931\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.9989 - loss: 0.0069 - val_accuracy: 0.8611 - val_loss: 1.9114\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.9974 - loss: 0.0696 - val_accuracy: 0.7639 - val_loss: 2.4315\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9940 - loss: 0.0118 - val_accuracy: 0.8194 - val_loss: 2.3589\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9888 - loss: 0.0294 - val_accuracy: 0.6944 - val_loss: 5.6090\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9955 - loss: 0.0275 - val_accuracy: 0.7222 - val_loss: 6.3253\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 0.7361 - val_loss: 5.9974\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9979 - loss: 0.0029 - val_accuracy: 0.7917 - val_loss: 4.2211\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 9.4249e-07 - val_accuracy: 0.8194 - val_loss: 3.1690\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9985 - loss: 0.0012 - val_accuracy: 0.8333 - val_loss: 2.8645\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9965 - loss: 0.0202 - val_accuracy: 0.8472 - val_loss: 2.4341\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 8.2784e-11 - val_accuracy: 0.8472 - val_loss: 2.5569\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 2.8376e-09 - val_accuracy: 0.8472 - val_loss: 2.6572\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9908 - loss: 0.1638 - val_accuracy: 0.8889 - val_loss: 2.6976\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.8750 - val_loss: 3.3241\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.0054e-06 - val_accuracy: 0.8889 - val_loss: 4.0534\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 1.6623e-07 - val_accuracy: 0.8750 - val_loss: 4.4170\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 1.5832e-09 - val_accuracy: 0.8611 - val_loss: 4.5868\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 2.6699e-08 - val_accuracy: 0.8611 - val_loss: 4.6664\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9993 - loss: 0.0011 - val_accuracy: 0.8889 - val_loss: 4.3515\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9985 - loss: 0.0103 - val_accuracy: 0.6944 - val_loss: 19.3137\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9985 - loss: 0.0591 - val_accuracy: 0.7500 - val_loss: 11.8786\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9955 - loss: 0.0083 - val_accuracy: 0.8750 - val_loss: 2.9242\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.8611 - val_loss: 3.6766\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 1.2047e-07 - val_accuracy: 0.8750 - val_loss: 2.4905\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9928 - loss: 0.0178 - val_accuracy: 0.8472 - val_loss: 4.4607\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9939 - loss: 0.0547 - val_accuracy: 0.8750 - val_loss: 3.3476\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9965 - loss: 0.0227 - val_accuracy: 0.8194 - val_loss: 4.1837\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 2.0025e-05 - val_accuracy: 0.8056 - val_loss: 5.3878\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.3464e-06 - val_accuracy: 0.8056 - val_loss: 5.8964\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9910 - loss: 0.0184 - val_accuracy: 0.8611 - val_loss: 7.7259\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9993 - loss: 0.0095 - val_accuracy: 0.8333 - val_loss: 10.5477\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8424 - loss: 10.4407\n",
            "accuracy: 0.8333333134651184\n",
            "elu 모델(배치 정규화로 정확도 높임) : 83.33333134651184%\n"
          ]
        }
      ],
      "source": [
        "# 모델 구성3-1 : elu 모델(배치 정규화로 정확도 높임)\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='elu', input_shape=(300, 300, 3)),\n",
        "    layers.BatchNormalization(), # 배치 정규화\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='elu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='elu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='elu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'elu 모델(배치 정규화로 정확도 높임) : {accuracy*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성4 : elu로 변경 후 컨볼루션 추가\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='elu', input_shape=(300,300, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='elu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='elu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(256, (3, 3), activation='elu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(512, (3, 3), activation='elu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'elu로 변경 후 컨볼루션 추가 모델 : {accuracy*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZQBvrBiO3Pu",
        "outputId": "d634e689-8148-4def-a8ee-ccbc22a7fa24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 335ms/step - accuracy: 0.6171 - loss: 18.3067 - val_accuracy: 0.4583 - val_loss: 28.4819\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.8180 - loss: 2.2065 - val_accuracy: 0.4583 - val_loss: 27.2162\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.8372 - loss: 1.3030 - val_accuracy: 0.5417 - val_loss: 3.5871\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9213 - loss: 0.2045 - val_accuracy: 0.5278 - val_loss: 4.1240\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9721 - loss: 0.0799 - val_accuracy: 0.5139 - val_loss: 3.9614\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9693 - loss: 0.0430 - val_accuracy: 0.5139 - val_loss: 4.2398\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9816 - loss: 0.0391 - val_accuracy: 0.5139 - val_loss: 3.3756\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.9908 - loss: 0.0267 - val_accuracy: 0.5139 - val_loss: 4.4290\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.5556 - val_loss: 3.7759\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9948 - loss: 0.0173 - val_accuracy: 0.5278 - val_loss: 4.9852\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9939 - loss: 0.0142 - val_accuracy: 0.5278 - val_loss: 6.1016\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5972 - val_loss: 5.7988\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.5972 - val_loss: 6.2954\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9979 - loss: 0.0115 - val_accuracy: 0.5972 - val_loss: 6.8989\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.6667 - val_loss: 6.9164\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6528 - val_loss: 7.4146\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.6944 - val_loss: 7.4851\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.9993 - loss: 0.0054 - val_accuracy: 0.6806 - val_loss: 7.7228\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8472 - val_loss: 7.5504\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9973 - loss: 0.0132 - val_accuracy: 0.6667 - val_loss: 8.3546\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.9901 - loss: 0.0079 - val_accuracy: 0.7917 - val_loss: 7.9151\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9908 - loss: 0.0102 - val_accuracy: 0.6528 - val_loss: 8.6826\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9958 - loss: 0.0087 - val_accuracy: 0.8472 - val_loss: 7.7310\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.6944 - val_loss: 8.3852\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.7917 - val_loss: 7.9862\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8333 - val_loss: 7.5790\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9965 - loss: 0.0042 - val_accuracy: 0.8056 - val_loss: 7.6867\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9979 - loss: 0.0035 - val_accuracy: 0.8472 - val_loss: 7.3556\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.9973 - loss: 0.0040 - val_accuracy: 0.8472 - val_loss: 7.2011\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8194 - val_loss: 7.1025\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8472 - val_loss: 6.7855\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 6.5145e-04 - val_accuracy: 0.8333 - val_loss: 6.4676\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8472 - val_loss: 6.2708\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8472 - val_loss: 5.8785\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8472 - val_loss: 5.5957\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 7.3522e-04 - val_accuracy: 0.8333 - val_loss: 5.4083\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9993 - loss: 9.6925e-04 - val_accuracy: 0.8333 - val_loss: 5.0555\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8333 - val_loss: 4.6753\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 6.8015e-04 - val_accuracy: 0.8472 - val_loss: 4.3498\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 5.9159e-04 - val_accuracy: 0.8472 - val_loss: 3.9599\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 8.1015e-04 - val_accuracy: 0.8472 - val_loss: 3.5682\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 3.6743e-04 - val_accuracy: 0.8472 - val_loss: 3.1323\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 6.0848e-04 - val_accuracy: 0.8472 - val_loss: 2.6846\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 5.0782e-04 - val_accuracy: 0.8472 - val_loss: 2.2014\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 7.7024e-04 - val_accuracy: 0.8472 - val_loss: 1.7285\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 7.5530e-04 - val_accuracy: 0.8611 - val_loss: 1.3029\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 3.1822e-04 - val_accuracy: 0.8611 - val_loss: 0.8465\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.5057e-04 - val_accuracy: 0.8750 - val_loss: 0.6501\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 3.8415e-04 - val_accuracy: 0.8611 - val_loss: 0.6626\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 5.0666e-04 - val_accuracy: 0.8750 - val_loss: 0.6758\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8789 - loss: 0.6567\n",
            "accuracy: 0.875\n",
            "elu로 변경 후 컨볼루션 추가 모델 : 87.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmX6xbyXAvrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9f4867-454c-4d17-a856-c4212ada5c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.5132 - loss: 62.1083 - val_accuracy: 0.5278 - val_loss: 2.9060\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5714 - loss: 2.2615 - val_accuracy: 0.7500 - val_loss: 0.4863\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8075 - loss: 0.4065 - val_accuracy: 0.6806 - val_loss: 0.6432\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8287 - loss: 0.3941 - val_accuracy: 0.7778 - val_loss: 0.4689\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8879 - loss: 0.2806 - val_accuracy: 0.7778 - val_loss: 0.4544\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9081 - loss: 0.2618 - val_accuracy: 0.8056 - val_loss: 0.4109\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9077 - loss: 0.2206 - val_accuracy: 0.7778 - val_loss: 0.4793\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8989 - loss: 0.2227 - val_accuracy: 0.8056 - val_loss: 0.4243\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9697 - loss: 0.1622 - val_accuracy: 0.8333 - val_loss: 0.3701\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9629 - loss: 0.1506 - val_accuracy: 0.8333 - val_loss: 0.3700\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9446 - loss: 0.1519 - val_accuracy: 0.8056 - val_loss: 0.3981\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9616 - loss: 0.1252 - val_accuracy: 0.7917 - val_loss: 0.5089\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9772 - loss: 0.0979 - val_accuracy: 0.8472 - val_loss: 0.3808\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9979 - loss: 0.0594 - val_accuracy: 0.8194 - val_loss: 0.3955\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9979 - loss: 0.0567 - val_accuracy: 0.8194 - val_loss: 0.4033\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0499 - val_accuracy: 0.8472 - val_loss: 0.4319\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0458 - val_accuracy: 0.8333 - val_loss: 0.4249\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9986 - loss: 0.0293 - val_accuracy: 0.8194 - val_loss: 0.4173\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9910 - loss: 0.0686 - val_accuracy: 0.7500 - val_loss: 0.7411\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9729 - loss: 0.0785 - val_accuracy: 0.8472 - val_loss: 0.4524\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9937 - loss: 0.0369 - val_accuracy: 0.8194 - val_loss: 0.4527\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9929 - loss: 0.0472 - val_accuracy: 0.8194 - val_loss: 0.4494\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.8194 - val_loss: 0.4486\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.8472 - val_loss: 0.4548\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8472 - val_loss: 0.4626\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8194 - val_loss: 0.4850\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.8194 - val_loss: 0.4862\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8333 - val_loss: 0.4875\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8472 - val_loss: 0.5563\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8333 - val_loss: 0.4942\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8194 - val_loss: 0.4982\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8194 - val_loss: 0.5017\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8333 - val_loss: 0.5126\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8333 - val_loss: 0.5164\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.8333 - val_loss: 0.5238\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.8333 - val_loss: 0.5636\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8056 - val_loss: 0.5255\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8333 - val_loss: 0.5662\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.8194 - val_loss: 0.5387\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8333 - val_loss: 0.5522\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8194 - val_loss: 0.5497\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8333 - val_loss: 0.5758\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7778 - val_loss: 0.5608\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8333 - val_loss: 0.5848\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8194 - val_loss: 0.5739\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8472 - val_loss: 0.6141\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.8194 - val_loss: 0.5823\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8472 - val_loss: 0.6111\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8194 - val_loss: 0.5929\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8333 - val_loss: 0.6046\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8424 - loss: 0.5295\n",
            "accuracy: 0.8333333134651184\n",
            "Leaky_ReLU 모델 : 83.33333134651184%\n"
          ]
        }
      ],
      "source": [
        "# 모델 구성5 : Leaky_ReLU 모델\n",
        "# 사용법 : actictation=layers.LeakyReLu(alpha=0.1) ->alpha 값 조정으로 기울기 0.1, 0.2, 0,3 비교\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(30, (3, 3), activation='linear', input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(60, (3, 3), activation=layers.LeakyReLU(alpha=0.1)),\n",
        "    # tensorflow.keras.layers 모델 안에 LeakyReLU가 있어서 Python에서 사용하기 위해서 layers. 추가\n",
        "    layers.MaxPooling2D((2, 2),  padding = 'same'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation=layers.LeakyReLU(alpha=0.1)),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'Leaky_ReLU 모델 : {accuracy*100}%')\n",
        "\n",
        "\n",
        "# alpha = 0.2 : 정확도 약 82% / alpha = 0.3 : 정확도 약 80%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성5-3 : Leaky_ReLU 모델로 변경 후 컨볼루션 추가\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='linear', input_shape=(300,300, 3)),\n",
        "    layers.MaxPooling2D((2, 2), padding = 'same'),\n",
        "    layers.Conv2D(64, (3, 3), activation=layers.LeakyReLU(alpha=0.1)),\n",
        "    layers.MaxPooling2D((2, 2), padding = 'same'),\n",
        "    layers.Conv2D(128, (3, 3), activation=layers.LeakyReLU(alpha=0.1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2), padding = 'same'),\n",
        "    layers.Conv2D(256, (3, 3), activation=layers.LeakyReLU(alpha=0.1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2), padding = 'same'),\n",
        "    layers.Conv2D(512, (3, 3), activation=layers.LeakyReLU(alpha=0.1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2), padding = 'same'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='elu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'Leaky_ReLU 모델로 변경 후 컨볼루션 추가 모델 : {accuracy*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDgpNg5PP1jo",
        "outputId": "19b0f296-696c-4e8a-ba84-3ba87b61a273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.5096 - loss: 12.6877 - val_accuracy: 0.5417 - val_loss: 7.5927\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.8108 - loss: 6.4630 - val_accuracy: 0.0833 - val_loss: 63.2312\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.8973 - loss: 1.9656 - val_accuracy: 0.0278 - val_loss: 107.6003\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.8975 - loss: 1.1830 - val_accuracy: 0.0278 - val_loss: 87.2097\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.9326 - loss: 0.2831 - val_accuracy: 0.0278 - val_loss: 186.5565\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9741 - loss: 0.0861 - val_accuracy: 0.0139 - val_loss: 257.8341\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9641 - loss: 0.0793 - val_accuracy: 0.0278 - val_loss: 277.7209\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9450 - loss: 0.1941 - val_accuracy: 0.0278 - val_loss: 299.9857\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.9774 - loss: 0.0359 - val_accuracy: 0.0278 - val_loss: 306.9897\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.9979 - loss: 0.0149 - val_accuracy: 0.0278 - val_loss: 301.8249\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9973 - loss: 0.0034 - val_accuracy: 0.0278 - val_loss: 299.8717\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.0278 - val_loss: 299.8411\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.0278 - val_loss: 298.4707\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9931 - loss: 0.2496 - val_accuracy: 0.0278 - val_loss: 316.0858\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9771 - loss: 0.2895 - val_accuracy: 0.0833 - val_loss: 199.0549\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9821 - loss: 0.0643 - val_accuracy: 0.1250 - val_loss: 109.3537\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9720 - loss: 0.1578 - val_accuracy: 0.0833 - val_loss: 170.9693\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9624 - loss: 0.1012 - val_accuracy: 0.0833 - val_loss: 228.8241\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9822 - loss: 0.0478 - val_accuracy: 0.0833 - val_loss: 269.4407\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9820 - loss: 0.0219 - val_accuracy: 0.0833 - val_loss: 270.9957\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9939 - loss: 0.0233 - val_accuracy: 0.0833 - val_loss: 270.2451\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.0833 - val_loss: 261.9818\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.0833 - val_loss: 249.5814\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.0833 - val_loss: 239.0367\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0972 - val_loss: 230.3861\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.1111 - val_loss: 218.9025\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9985 - loss: 0.0020 - val_accuracy: 0.1389 - val_loss: 202.7388\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 9.7675e-04 - val_accuracy: 0.1528 - val_loss: 186.4574\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.1528 - val_loss: 172.7707\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 3.3613e-04 - val_accuracy: 0.1528 - val_loss: 156.6923\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.1528 - val_loss: 136.0863\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 9.2879e-04 - val_accuracy: 0.1667 - val_loss: 116.0801\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 6.4473e-04 - val_accuracy: 0.2083 - val_loss: 99.8016\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 7.8082e-04 - val_accuracy: 0.2083 - val_loss: 65.7038\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.3333 - val_loss: 32.9327\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.4167 - val_loss: 19.5787\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 3.9530e-04 - val_accuracy: 0.5694 - val_loss: 11.2351\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 2.4827e-04 - val_accuracy: 0.7083 - val_loss: 5.7137\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 2.1334e-04 - val_accuracy: 0.7500 - val_loss: 3.5919\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.4724e-04 - val_accuracy: 0.8333 - val_loss: 2.7449\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 5.2679e-04 - val_accuracy: 0.8611 - val_loss: 2.2721\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 2.0824e-04 - val_accuracy: 0.8611 - val_loss: 2.2774\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.3284e-04 - val_accuracy: 0.8472 - val_loss: 2.4002\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.8055e-04 - val_accuracy: 0.8472 - val_loss: 2.5398\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 5.8651e-04 - val_accuracy: 0.8472 - val_loss: 2.6595\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 2.0431e-04 - val_accuracy: 0.8472 - val_loss: 2.7726\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 1.4270e-04 - val_accuracy: 0.8472 - val_loss: 2.9000\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 2.2602e-04 - val_accuracy: 0.8611 - val_loss: 2.9749\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 4.2460e-04 - val_accuracy: 0.8333 - val_loss: 3.1282\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 1.2076e-04 - val_accuracy: 0.8472 - val_loss: 3.2192\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8611 - loss: 4.1542\n",
            "accuracy: 0.8472222089767456\n",
            "Leaky_ReLU 모델로 변경 후 컨볼루션 추가 모델 : 84.72222089767456%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold 적용 후 정확도 산출_기본 설정\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 5겹 교차 검증\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=22)\n",
        "\n",
        "# 정확도 저장 리스트 초기화\n",
        "accuracy_scores = []\n",
        "# k-fold 수행\n",
        "for train_index, test_index in kfold.split(images, labels):\n",
        "  x_train, x_test = images[train_index], images[test_index]\n",
        "  y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "# 모델 구성2 : 컨볼루션 추가(정확도가 높았음)\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300,300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "# 예측\n",
        "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "# 정확도 계산 후 저장\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_scores.append(accuracy)\n",
        "\n",
        "# 평균 정확도 출력\n",
        "print(f'accuracy : {np.mean(accuracy_scores)}')\n",
        "print(f'k-fold 적용 정확도 : {np.mean(accuracy_scores)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wndm6hsXDyu1",
        "outputId": "11711c12-45f5-4f04-a99b-95e61486a7ed"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - accuracy: 0.4839 - loss: 1.2779 - val_accuracy: 0.4583 - val_loss: 0.7508\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.5989 - loss: 0.6648 - val_accuracy: 0.7222 - val_loss: 0.5433\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.7284 - loss: 0.5215 - val_accuracy: 0.7361 - val_loss: 0.5267\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.7959 - loss: 0.4109 - val_accuracy: 0.8611 - val_loss: 0.3185\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8362 - loss: 0.2901 - val_accuracy: 0.8472 - val_loss: 0.2907\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.8936 - loss: 0.2427 - val_accuracy: 0.9167 - val_loss: 0.1913\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9520 - loss: 0.1222 - val_accuracy: 0.9306 - val_loss: 0.1667\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9530 - loss: 0.0970 - val_accuracy: 0.9167 - val_loss: 0.1970\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9909 - loss: 0.0428 - val_accuracy: 0.9167 - val_loss: 0.2411\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9962 - loss: 0.0251 - val_accuracy: 0.9167 - val_loss: 0.2758\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.9979 - loss: 0.0161 - val_accuracy: 0.9306 - val_loss: 0.2123\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9028 - val_loss: 0.2746\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9167 - val_loss: 0.4463\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9167 - val_loss: 0.5146\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9167 - val_loss: 0.5467\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 5.8328e-04 - val_accuracy: 0.9028 - val_loss: 0.4834\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.3635e-04 - val_accuracy: 0.9167 - val_loss: 0.5320\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 8.6310e-05 - val_accuracy: 0.9167 - val_loss: 0.5684\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.5696e-04 - val_accuracy: 0.9167 - val_loss: 0.5698\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.1973e-04 - val_accuracy: 0.9167 - val_loss: 0.5720\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 1.1733e-04 - val_accuracy: 0.9167 - val_loss: 0.5867\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 4.7772e-05 - val_accuracy: 0.9167 - val_loss: 0.5869\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 4.2970e-05 - val_accuracy: 0.9167 - val_loss: 0.5963\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.0157e-05 - val_accuracy: 0.9167 - val_loss: 0.5950\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.1231e-05 - val_accuracy: 0.9167 - val_loss: 0.6055\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 1.5814e-05 - val_accuracy: 0.9167 - val_loss: 0.6181\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 2.3691e-05 - val_accuracy: 0.9167 - val_loss: 0.6183\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 1.6601e-05 - val_accuracy: 0.9167 - val_loss: 0.6219\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 2.2255e-05 - val_accuracy: 0.9167 - val_loss: 0.6246\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.1785e-05 - val_accuracy: 0.9167 - val_loss: 0.6281\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 9.8152e-06 - val_accuracy: 0.9167 - val_loss: 0.6336\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 1.5107e-05 - val_accuracy: 0.9167 - val_loss: 0.6403\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 6.3977e-06 - val_accuracy: 0.9167 - val_loss: 0.6423\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.6823e-05 - val_accuracy: 0.9167 - val_loss: 0.6448\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.4334e-05 - val_accuracy: 0.9167 - val_loss: 0.6480\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 5.4574e-06 - val_accuracy: 0.9167 - val_loss: 0.6490\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 1.1609e-05 - val_accuracy: 0.9167 - val_loss: 0.6519\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 1.1080e-05 - val_accuracy: 0.9167 - val_loss: 0.6537\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 6.5948e-06 - val_accuracy: 0.9167 - val_loss: 0.6535\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 5.1620e-06 - val_accuracy: 0.9167 - val_loss: 0.6585\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.2313e-06 - val_accuracy: 0.9167 - val_loss: 0.6567\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 5.2245e-06 - val_accuracy: 0.9167 - val_loss: 0.6593\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 7.1677e-06 - val_accuracy: 0.9167 - val_loss: 0.6622\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 3.4238e-06 - val_accuracy: 0.9167 - val_loss: 0.6612\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.3153e-06 - val_accuracy: 0.9167 - val_loss: 0.6634\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 4.3159e-06 - val_accuracy: 0.9167 - val_loss: 0.6654\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 6.0742e-06 - val_accuracy: 0.9167 - val_loss: 0.6654\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 3.1418e-06 - val_accuracy: 0.9167 - val_loss: 0.6680\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 4.2600e-06 - val_accuracy: 0.9167 - val_loss: 0.6667\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 5.7190e-06 - val_accuracy: 0.9167 - val_loss: 0.6672\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "accuracy : 0.9166666666666666\n",
            "k-fold 적용 정확도 : 91.66666666666666%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold 적용 후 정확도 산출_기본 설정\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 5겹 교차 검증\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=22)\n",
        "\n",
        "# 정확도 저장 리스트 초기화\n",
        "accuracy_scores = []\n",
        "# k-fold 수행\n",
        "for train_index, test_index in kfold.split(images, labels):\n",
        "  x_train, x_test = images[train_index], images[test_index]\n",
        "  y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "# 모델 구성2 : 컨볼루션 추가(정확도가 높았음)\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), strides=(1, 1), activation='relu', input_shape=(300,300, 3)),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(128, (3, 3), strides=(1, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(512, (3, 3), strides=(1, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "# strides=(2, 2)로 설정시 padding=same으로 설정해서 컨볼루션 연산 불가능 -> (1, 1)로 설정\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "# 예측\n",
        "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "# 정확도 계산 후 저장\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_scores.append(accuracy)\n",
        "\n",
        "# 평균 정확도 출력\n",
        "print(f'accuracy : {np.mean(accuracy_scores)}')\n",
        "print(f'k-fold / stride  적용 정확도 : {np.mean(accuracy_scores)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emz0-clpaPJQ",
        "outputId": "3d093d77-5a6b-43bf-d602-9b721afc395b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 325ms/step - accuracy: 0.5418 - loss: 2.0186 - val_accuracy: 0.4583 - val_loss: 0.7858\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.4906 - loss: 0.7223 - val_accuracy: 0.7222 - val_loss: 0.6335\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.7510 - loss: 0.5828 - val_accuracy: 0.8056 - val_loss: 0.4496\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.8014 - loss: 0.4349 - val_accuracy: 0.8472 - val_loss: 0.3778\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.8077 - loss: 0.3849 - val_accuracy: 0.8611 - val_loss: 0.2769\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.8678 - loss: 0.2964 - val_accuracy: 0.9028 - val_loss: 0.1865\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9151 - loss: 0.2567 - val_accuracy: 0.9167 - val_loss: 0.2095\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9314 - loss: 0.1477 - val_accuracy: 0.9028 - val_loss: 0.1602\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9689 - loss: 0.0993 - val_accuracy: 0.9583 - val_loss: 0.0595\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9544 - loss: 0.0927 - val_accuracy: 0.9306 - val_loss: 0.1406\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9582 - loss: 0.1214 - val_accuracy: 0.9167 - val_loss: 0.1828\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9683 - loss: 0.0820 - val_accuracy: 0.9444 - val_loss: 0.1387\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9881 - loss: 0.0194 - val_accuracy: 0.9722 - val_loss: 0.0848\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9985 - loss: 0.0087 - val_accuracy: 0.9583 - val_loss: 0.1838\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9444 - val_loss: 0.1476\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9722 - val_loss: 0.0441\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9722 - val_loss: 0.0432\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9722 - val_loss: 0.0982\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.4899e-04 - val_accuracy: 0.9722 - val_loss: 0.0914\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 2.7475e-04 - val_accuracy: 0.9722 - val_loss: 0.1041\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 1.0884e-04 - val_accuracy: 0.9722 - val_loss: 0.1143\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 2.0140e-05 - val_accuracy: 0.9583 - val_loss: 0.1470\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 1.7629e-05 - val_accuracy: 0.9444 - val_loss: 0.1918\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.7612e-05 - val_accuracy: 0.9444 - val_loss: 0.2231\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.0249e-05 - val_accuracy: 0.9444 - val_loss: 0.3003\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 4.9639e-06 - val_accuracy: 0.9444 - val_loss: 0.3322\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 3.9602e-06 - val_accuracy: 0.9444 - val_loss: 0.3514\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 4.3047e-06 - val_accuracy: 0.9444 - val_loss: 0.3811\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 3.3336e-06 - val_accuracy: 0.9444 - val_loss: 0.3979\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 3.1316e-06 - val_accuracy: 0.9444 - val_loss: 0.4411\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 1.1589e-06 - val_accuracy: 0.9444 - val_loss: 0.4504\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 8.0114e-07 - val_accuracy: 0.9444 - val_loss: 0.4597\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 1.7152e-06 - val_accuracy: 0.9444 - val_loss: 0.4834\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 1.1804e-06 - val_accuracy: 0.9444 - val_loss: 0.5013\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 7.8741e-07 - val_accuracy: 0.9444 - val_loss: 0.5091\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 4.3889e-07 - val_accuracy: 0.9444 - val_loss: 0.5139\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 5.9705e-07 - val_accuracy: 0.9444 - val_loss: 0.5309\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 4.5257e-07 - val_accuracy: 0.9444 - val_loss: 0.5368\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 4.8019e-07 - val_accuracy: 0.9444 - val_loss: 0.5457\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 7.1440e-07 - val_accuracy: 0.9444 - val_loss: 0.5581\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 3.0600e-07 - val_accuracy: 0.9444 - val_loss: 0.5671\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.6012e-07 - val_accuracy: 0.9444 - val_loss: 0.5770\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.7452e-07 - val_accuracy: 0.9444 - val_loss: 0.5807\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.9460e-07 - val_accuracy: 0.9444 - val_loss: 0.5849\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 3.4316e-07 - val_accuracy: 0.9444 - val_loss: 0.5892\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 3.3702e-07 - val_accuracy: 0.9444 - val_loss: 0.5935\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 4.6950e-07 - val_accuracy: 0.9444 - val_loss: 0.6017\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.7803e-07 - val_accuracy: 0.9444 - val_loss: 0.6091\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.4323e-07 - val_accuracy: 0.9444 - val_loss: 0.6116\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.0418e-07 - val_accuracy: 0.9444 - val_loss: 0.6127\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
            "accuracy : 0.9444444444444444\n",
            "k-fold / stride  적용 정확도 : 94.44444444444444%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}